---
title: "exploratory analysis of auto-regression of biosensors"
output: html_document
date: "2023-11-10"
---


# Overview
dysregulation in physio system is a predictor of aggressive behavior (or sib, ed)
dysregulation is measured by dynamics in EDA, hand movements, bvp

To examine: effect of AR(1) of EDA, accelerometer, BVP on aggressive behavior
Expect: Higher AR indicates emotion dysregulation, and elicits higher aggressive behavior

Prelim result:
Precision-recall is low for prediction of aggressive behavior based on biosensor AR, including xgboosting, multilevel modeling (generalized)



````{r}

library(ggplot2)
library(dplyr)
library(lmerTest)
library(lme4)
library(lubridate)
library(psych)
library(pompom)

library(zoo)
library(xgboost)
library(reshape2)

library(pROC)
library(PRROC)

library(lme4)
library(lmerTest)

library(caret)
set.seed(1234)
```
 


```{r}
path <- getwd()
setwd(path)
# all_data <- read.csv("all_data.csv", nrows = 200)
# all_data <- read.csv("all_data.csv")
# 
# all_data$episode <- as.numeric(substring(all_data$file,9,10))

```

```{r}
window_data_collect <-read.csv("exploratory_ar_df.csv" )


cor.plot(window_data_collect[,6:ncol(window_data_collect)])

```


```{r}


id_list <- unique(window_data_collect$id)
time_window <- 180 # seconds
predict_window <- 60 # seconds
sampling_rate <- 4
sliding_unit <- 15 * sampling_rate # data points, 60 seconds
```

# summary statistics for aggressive beahvior by id
```{r}


total_id <- length(id_list)
total_id
window_data_collect$predict_ed_bin <-ifelse(window_data_collect$predict_ed >0,1,0)
# each data point is a 15-second window
summarize_id <- data.frame(
  window_data_collect %>% 
    group_by(id) %>% 
    summarize(
      ed_behavior = sum(predict_ed_bin, na.rm =T), # how many windows have aggressive behavior
      total_duration = n()/4/60 #hence this is the hours of data
  )
)
summarize_id

describe(summarize_id)

# how many id had zero aggressive behavior
zero_ed_id <- summarize_id[summarize_id$ed_behavior==0,]$id
length(zero_ed_id)
# 35 ID had zero aggressive behavior
```



















```{r}

window_data_collect$predict_ed_bin <- ifelse(window_data_collect$predict_ed>0 , 1,0)
# 
# table(window_data_collect$predict_agg_bin)
# 808 aggressive behavior out of 41k 1-minute window

table(window_data_collect$predict_ed_bin)
```

```{r}
# fewer onset of aggressive behavior

window_data_collect$ed_onset <- ifelse(window_data_collect$predict_ed>0 &  
                                          lag(window_data_collect$predict_ed,1)==0, 1,0)
# 
table(window_data_collect$ed_onset)
# 128 aggressive beahvior onset out of 41k 1-minute window
```
```{r}
id_ed<- data.frame(window_data_collect %>% 
                       group_by(id) %>% 
                       summarise(
                         ed_count = sum(predict_ed_bin, na.rm = T)))
table(id_ed$ed_count)
# distribution of ID's aggressive episode counts, e.g., 35 participants had 0 aggressive behavior (defined as in the 1-minute window, so not strictly speaking an episode)

```


# apply ML on this 

## split training and testing set
This was done in the fashion of time-series prediction, select the first 80% rows of each id as training set, and the rest 20% as testing set.

Note here "window_data_collect" data frame is the "aggregated" data frame after computing each moving window's data summary (15 seconds). That's why we needed to multiply the index by sliding_unit (15 seconds * 4 sampling/second) plus the initial biosensor window (3 minute * 60 seconds * 4sampling/second = 720) 
```{r}

id_80percent <- data.frame(window_data_collect %>%
                             group_by(id, session, episode) %>% 
                             summarise(eighty_percent_rows = round(n() * .8,0)))

window_data_collect_new <- merge(window_data_collect,
                                 id_80percent,by=c("id" , "session", "episode"))

training_set <- window_data_collect[window_data_collect_new$row <= 
                                      (window_data_collect_new$eighty_percent_rows -1)* sliding_unit + time_window * sampling_rate,]

nrow(training_set)/nrow(window_data_collect)

testing_set <- window_data_collect_new[window_data_collect_new$row >
                                      (window_data_collect_new$eighty_percent_rows -1)* sliding_unit + time_window * sampling_rate,]

```

## select features
```{r}

selected_features <- c("mean_eda",
                       "mean_acc_distance",
                       "mean_bvp",
                       
                       "eda_ar",
                       "acc_ar",
                       "bvp_ar")
```

## xgboosting as prediction method
```{r}
xgb_model <- xgboost(data = as.matrix(training_set[c(selected_features)]),
                       label =training_set$predict_ed_bin,
                       max.depth = 5,
                       eta = 1,
                       nthread = 5,
                       nrounds = 100,
                       objective = "binary:logistic")
  

importance_matrix = xgb.importance(selected_features, model = xgb_model)
importance_matrix

xgb.plot.importance(importance_matrix)
```



```{r}
# validate using testing set
testing_set$prediction <- predict(xgb_model, newdata =as.matrix( testing_set[c(selected_features)]))

```


### check accuracy
```{r}


roc_model <- roc(
 testing_set$predict_ed_bin,
 testing_set$prediction)

plot(roc_model, print.auc=TRUE)
```
### precision-recall AUC

Precision-recall AUC is low. 
```{r}

pr<-pr.curve(scores.class0=testing_set$predict_ed_bin,
             scores.class1=testing_set$prediction, 
             curve = T)
pr
plot(pr)
```



## Generalized multilevel modeling as a prediction method
```{r}

m1 <- glmer(predict_ed_bin~
              mean_eda +
              eda_ar+
              mean_acc_distance +
              acc_ar+
              mean_bvp + 
              bvp_ar + 
             (1 |id), 
          data =training_set, 
          family = "binomial")
summary(m1)

```

```{r}
# test roc
testing_set$glmer_prediction <- predict(m1, testing_set, type = "response")

describe(testing_set$glmer_prediction )
```

```{r}
glmer_roc_model <- roc(
 testing_set$predict_ed_bin,
 testing_set$glmer_prediction)

plot(glmer_roc_model, print.auc=TRUE)


# precision recall auc
testing_set <- testing_set[!is.na(testing_set$glmer_prediction),]

pr<-pr.curve(scores.class0=testing_set$predict_ed_bin,
             scores.class1=testing_set$glmer_prediction, 
             curve = T)
pr
plot(pr)
```


# Check if eda is caused by ed
use lag-4,5,6 aggressive behavior (because of the 3 minute biosensor window and 1 minute aggressive behavior window) to predict current eda, the corresponding EDA and lag-1 aggressive behavior should be the aggressive behavior of 4,5,6 minute ago
```{r}
window_data_collect$lag_ed <-
  lag(window_data_collect$predict_ed,4)+
  lag(window_data_collect$predict_ed,5)+
  lag(window_data_collect$predict_ed,6)

m2 <- lmer(mean_eda~
             lag_ed +
             (1 |id), 
          data =window_data_collect )
summary(m2)
```

### test on outcome as onset of aggression
```{r}


m3 <- glmer(ed_onset~
              mean_eda + 
              eda_ar+
              mean_acc_distance + 
              acc_ar+
              mean_bvp + 
              bvp_ar + 
             (1 |id), 
          data =training_set, 
          family = "binomial")
summary(m3)
```

```{r}
# test roc
testing_set$ed_onset_glmer_prediction <- predict(m3, testing_set, type = "response")

describe(testing_set$ed_onset_glmer_prediction )
table(testing_set$ed_onset )
```

```{r}
glmer_roc_model <- roc(
 testing_set$ed_onset,
 testing_set$ed_onset_glmer_prediction)

plot(glmer_roc_model, print.auc=TRUE)


# precision recall auc
testing_set <- testing_set[!is.na(testing_set$ed_onset_glmer_prediction),]

pr<-pr.curve(scores.class0=testing_set$ed_onset,
             scores.class1=testing_set$ed_onset_glmer_prediction, 
             curve = T)
pr
plot(pr)
```



```{r}

ggplot(data = window_data_collect, aes(x = mean_acc_distance, y = ed_onset, group = id))+
  geom_point()+
  geom_smooth(method = "loess", se = F)+
  facet_wrap(~id)
```






# Person-specific
```{r}

non_zero_ed_id <- setdiff(id_list, zero_ed_id)

prauc_df <- NULL
importance_matrix_df_collect <- NULL

for (id in non_zero_ed_id){
  id_data <- training_set[training_set$id == id,]
  id_data_testing <- testing_set[testing_set$id == id,]
  
  id_data$session_episode <- paste(id_data$session, id_data$episode, sep ="_")
  id_data_testing$session_episode <- paste(id_data_testing$session, id_data_testing$episode, sep ="_")
  nested_no <- length(unique(id_data$session_episode))

  if (mean(id_data$ed_onset,na.rm=T) !=0 &
      mean(id_data_testing$ed_onset,na.rm=T) !=0){

        
    xgb_model <- xgboost(data = as.matrix(id_data[c(selected_features)]),
                           label =id_data$ed_onset,
                           max.depth = 5,
                           eta = 1,
                           nthread = 5,
                           nrounds = 100,
                           objective = "binary:logistic")
        
    importance_matrix = xgb.importance(selected_features, model = xgb_model)
    importance_matrix_df <- data.frame(importance_matrix)
    importance_matrix_df$id <- rep(id, nrow(importance_matrix_df))
    importance_matrix_df_collect <-rbind(importance_matrix_df_collect,
                                       importance_matrix_df)

    id_data_testing$prediction <- predict(xgb_model,                                          as.matrix(id_data_testing[c(selected_features)]), 
                                          type = "response")
    
        
    roc_model <- roc(
     id_data_testing$ed_onset,
     id_data_testing$prediction)
    
    pr<-pr.curve(scores.class0=id_data_testing$ed_onset,
                 scores.class1=id_data_testing$prediction, 
                 curve = T)
    
    prauc_df <-rbind(prauc_df, c(id,pr$auc.integral ))
    print(id)
  }
}

prauc_df <- data.frame(prauc_df)
names(prauc_df) <-c("id","prauc")
```

```{r}

prauc_df <- prauc_df[order(-prauc_df$prauc),]
prauc_df
describe(prauc_df)
```
